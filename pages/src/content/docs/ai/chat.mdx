---
title: 对话与流式
description: 如何配置对话模型、流式输出与系统提示
sidebar:
    order: 2
---

import { Aside } from '@astrojs/starlight/components';

本文说明如何用 Feat AI 完成单轮/多轮对话、流式输出、系统提示等常见任务。假设你已能创建 `ChatModel`（见 [开始使用](/feat/ai/getstart/)）。

## 任务描述

- 配置对话模型（baseUrl、模型、API Key、系统提示等）
- 发送单条消息并获取完整回复（同步）
- 以流式方式逐段接收回复
- 设置系统提示（角色/风格）或关闭“思考”输出（部分模型）

## 解决方案

### 创建对话模型

通过 `FeatAI.chatModel(opts -> ...)` 创建，常用配置：

| 配置 | 方法 | 说明 |
|------|------|------|
| 服务地址 | `baseUrl(String)` | 兼容 OpenAI 的 API 根地址，如 Ollama 的 `http://localhost:11434/v1` |
| 模型 | `model(String)` 或 `model(ChatModelVendor)` | 模型名或内置厂商枚举 |
| API Key | `apiKey(String)` 或环境变量 `FEAT_AI_API_KEY` | 云端 API 必填 |
| 系统提示 | `system(String)` | 设定角色或风格，如「你是一个诗人」 |
| 调试 | `debug(boolean)` | 为 true 时打印请求/响应便于排查 |
| 关闭思考 | `noThink(true)` | 部分模型会输出“思考”内容，设为 true 可关闭 |

示例：本地 Ollama + 系统提示 + 关闭思考：

```java
ChatModel model = FeatAI.chatModel(opts -> opts
        .baseUrl("http://localhost:11434/v1")
        .model("qwen2.5:7b")
        .system("你是一个擅长生成藏头诗的诗人。")
        .noThink(true)
);
```

### 同步对话：chat()

单条消息、一次性拿到完整回复和用量信息：

```java
model.chat("根据关键词「情」「人」「节」生成一句藏头诗", response -> {
    System.out.println(response.getContent());
    System.out.println(response.getUsage());
});
```

多轮对话可自行维护消息列表，并调用支持 `List<Message>` 的接口（见 API 参考）。

### 流式对话：chatStream()

逐段输出，适合长回答或实时展示。回调中可区分「内容片段」与「完成」：

```java
model.chatStream("用三句话介绍 Feat 框架", new StreamResponseCallback() {
    @Override
    public void onStreamResponse(String content) {
        System.out.print(content);
    }

    @Override
    public void onCompletion(ResponseMessage responseMessage) {
        System.out.println("\n生成完成");
    }
});
```

<Aside type="tip">
流式接口还有仅传 `(String content) -> ...` 的简化写法，只处理内容片段，不处理完成事件。
</Aside>

### 完整示例（基于 feat-ai demo）

下面示例来自 `feat-ai` 模块的 `OllamaDemo`，演示：创建模型、系统提示、流式与同步两种调用方式（JDK 8 可运行）：

```java
import tech.smartboot.feat.ai.FeatAI;
import tech.smartboot.feat.ai.chat.ChatModel;
import tech.smartboot.feat.ai.chat.entity.ResponseMessage;
import tech.smartboot.feat.ai.chat.entity.StreamResponseCallback;

public class ChatDemoExample {
    public static void main(String[] args) {
        ChatModel model = FeatAI.chatModel(opts -> opts
                .baseUrl("http://localhost:11434/v1")
                .model("qwen2.5:7b")
                .system("你是一个擅长生成藏头诗的诗人。")
                .noThink(true)
        );

        String prompt = "根据以下关键词生成一句藏头诗：情,人,节,快,乐";

        // 流式
        model.chatStream(prompt, new StreamResponseCallback() {
            @Override
            public void onStreamResponse(String content) {
                System.out.print(content);
            }
            @Override
            public void onCompletion(ResponseMessage responseMessage) {
                System.out.println("\n生成完成！");
            }
        });

        // 同步
        model.chat(prompt, response -> {
            System.out.println(response.getContent());
            System.out.println("生成完成！");
        });
    }
}
```

## 替代方案

- **Gitee AI**：使用 `opts.model(ChatModelVendor.GiteeAI.Qwen2_5_72B_Instruct)` 等，并设置 `FEAT_AI_API_KEY`，无需手动写 baseUrl。
- **自定义 baseUrl**：任意兼容 OpenAI 格式的接口均可通过 `baseUrl(...)` + `model(...)` 对接。

## 注意事项

- 使用 Gitee AI 时 **必须** 设置环境变量 `FEAT_AI_API_KEY`，否则会抛出 `IllegalArgumentException`。
- Ollama 的 baseUrl 通常为 `http://localhost:11434/v1`，且不要以 `/` 结尾；Feat AI 会自动去掉末尾斜杠。
- 部分模型会先输出“思考”再输出答案，若不需要可设置 `noThink(true)`。
- 流式回调可能在非主线程执行，若在 UI 或其它线程敏感场景使用，需自行做线程切换。

## 相关链接

- [开始使用 Feat AI](/feat/ai/getstart/)：首次创建 `ChatModel`
- [Feat AI 简介](/feat/ai/about/)：模块能力概览
- 项目内可运行示例：`feat-ai` 模块 `demo` 包下的 `ChatDemo`、`OllamaDemo`、`LocalAI`
